{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Need numpy 1.23.1\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "from shaphypetune import BoostSearch, BoostRFE, BoostRFA, BoostBoruta\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from hyperopt import hp\n",
    "from hyperopt import Trials\n",
    "from lightgbm import *\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917, 2841)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "train_df = pd.read_csv('./Data/train_final.csv')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix datetime columns to be relative floating points\n",
    "\n",
    "object_cols = train_df.select_dtypes(include=['O']).columns\n",
    "ref = datetime(2017, 1, 1)\n",
    "\n",
    "for col in object_cols:\n",
    "    if 'latest' in col or 'earliest' in col:\n",
    "        train_df[col] = (pd.to_datetime(train_df[col]) - ref).dt.total_seconds() / 3600.0\n",
    "\n",
    "# Remove remaining features of type Object\n",
    "\n",
    "train_df = train_df.drop(columns=train_df.select_dtypes(include=['O']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round all floats to 3 decimal places\n",
    "\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].dtype in ['float', 'float32', 'float64'] and col != 'target':\n",
    "        train_df[col] = train_df[col].round(3)\n",
    "\n",
    "# Reduce memory size\n",
    "\n",
    "for col in train_df.columns:\n",
    "    if col == 'target':\n",
    "        continue\n",
    "    elif train_df[col].dtype == 'float64':\n",
    "        max_float32 = train_df[col].astype('float32').max()\n",
    "        min_float32 = train_df[col].astype('float32').min()\n",
    "        if (train_df[col].max() == max_float32) and (train_df[col].min() == min_float32):\n",
    "            train_df[col] = train_df[col].astype('float32')\n",
    "    elif train_df[col].dtype == 'int64':\n",
    "        max_int32 = train_df[col].astype('int32').max()\n",
    "        min_int32 = train_df[col].astype('int32').min()\n",
    "        if (train_df[col].max() == max_int32) and (train_df[col].min() == min_int32):\n",
    "            train_df[col] = train_df[col].astype('int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201917 entries, 0 to 201916\n",
      "Columns: 2815 entries, feature_1 to subsector_max_spent\n",
      "dtypes: bool(15), float32(1885), float64(639), int32(276)\n",
      "memory usage: 2.6 GB\n"
     ]
    }
   ],
   "source": [
    "# Check memory usage\n",
    "\n",
    "train_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and scale the data\n",
    "\n",
    "X_dev_df, X_test_df, y_dev, y_test = train_test_split(train_df.drop(['target'], axis=1), train_df['target'], test_size=0.2, shuffle=True, random_state=42)\n",
    "X_train_df, X_val_df, y_train, y_val = train_test_split(X_dev_df, y_dev, test_size=0.25, random_state=42)\n",
    "\n",
    "X_columns = X_train_df.columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_df)\n",
    "X_dev = scaler.transform(X_dev_df)\n",
    "X_val = scaler.transform(X_val_df)\n",
    "X_test = scaler.transform(X_test_df)\n",
    "\n",
    "# Convert dataframes to scaled version\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train, columns=X_columns)\n",
    "X_dev_df = pd.DataFrame(X_dev, columns=X_columns)\n",
    "X_val_df = pd.DataFrame(X_val, columns=X_columns)\n",
    "X_test_df = pd.DataFrame(X_test, columns=X_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE Baseline: 3.7897541823325707\n"
     ]
    }
   ],
   "source": [
    "# Create XGBoost Regressor with default parameters as a baseline\n",
    "\n",
    "xgb_baseline = XGBRegressor(tree_method='gpu_hist')\n",
    "xgb_baseline.fit(X_dev, y_dev)\n",
    "xgb_baseline_rmse = np.sqrt(mean_squared_error(y_test, xgb_baseline.predict(X_test)))\n",
    "\n",
    "print(f'XGB RMSE Baseline: {xgb_baseline_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold selected features of future models\n",
    "\n",
    "selected_features = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "xgb_boruta_shap = XGBRegressor(n_estimators=150, random_state=0, verbosity=0, n_jobs=-1, tree_method='gpu_hist')\n",
    "\n",
    "model_boruta_shap = BoostBoruta(\n",
    "    xgb_boruta_shap, max_iter=200, perc=100,\n",
    "    importance_type='shap_importances', train_importance=False\n",
    ")\n",
    "\n",
    "model_boruta_shap.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=5, verbose=0, eval_metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "\n",
    "features = X_columns[model_boruta_shap.support_]\n",
    "importances = model_boruta_shap.estimator_.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features, \n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color=sns.color_palette(\"viridis\", len(importance_df['Feature'])))\n",
    "plt.xlabel('Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.title('Feature Importance Plot', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Model Score on Test Set, Raw\n",
    "\n",
    "xgb_boruta_shap_train_rmse = np.sqrt(mean_squared_error(y_test, model_boruta_shap.predict(X_test)))\n",
    "print(f'XGB RMSE Boruta SHAP (trained on train): {xgb_boruta_shap_train_rmse}')\n",
    "\n",
    "# Model Score on Test Set, Trained on Dev\n",
    "\n",
    "xgb_boruta_shap_dev = XGBRegressor(n_estimators=150, random_state=0, verbosity=0, n_jobs=-1, tree_method='gpu_hist')\n",
    "xgb_boruta_shap_dev.fit(X_dev_df[features], y_dev)\n",
    "xgb_boruta_shap_dev_rmse = np.sqrt(mean_squared_error(y_test, xgb_boruta_shap_dev.predict(X_test_df[features])))\n",
    "print(f'XGB RMSE Boruta SHAP (trained on dev): {xgb_boruta_shap_dev_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model, feature names and importances\n",
    "\n",
    "model_boruta_shap.estimator_.save_model(\"model_boruta_shap.json\")\n",
    "\n",
    "selected_features['boruta_shap'] = (features.to_list(), importances.to_list())\n",
    "with open('./models/features.txt', 'w') as file:\n",
    "    json.dump(selected_features, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "xgb_rfe_shap = XGBRegressor(n_estimators=150, random_state=0, verbosity=0, n_jobs=-1, tree_method='gpu_hist')\n",
    "\n",
    "model_rfe_shap = BoostRFE(\n",
    "    xgb_rfe_shap, min_features_to_select=10, step=50,\n",
    "    importance_type='shap_importances', train_importance=False\n",
    ")\n",
    "\n",
    "model_rfe_shap.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=5, verbose=0, eval_metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "\n",
    "features = X_columns[model_rfe_shap.support_]\n",
    "importances = model_rfe_shap.estimator_.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features, \n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color=sns.color_palette(\"viridis\", len(importance_df['Feature'])))\n",
    "plt.xlabel('Importance', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "plt.title('Feature Importance Plot', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.show()\n",
    "\n",
    "# Model Score on Test Set, Raw\n",
    "\n",
    "xgb_rfe_shap_train_rmse = np.sqrt(mean_squared_error(y_test, model_rfe_shap.predict(X_test)))\n",
    "print(f'XGB RMSE RFE SHAP (trained on train): {xgb_rfe_shap_train_rmse}')\n",
    "\n",
    "# Model Score on Test Set, Trained on Dev\n",
    "\n",
    "xgb_rfe_shap_dev = XGBRegressor(n_estimators=150, random_state=0, verbosity=0, n_jobs=-1, tree_method='gpu_hist')\n",
    "xgb_rfe_shap_dev.fit(X_dev_df[features], y_dev)\n",
    "xgb_rfe_shap_dev_rmse = np.sqrt(mean_squared_error(y_test, xgb_rfe_shap_dev.predict(X_test_df[features])))\n",
    "print(f'XGB RMSE RFE SHAP (trained on dev): {xgb_rfe_shap_dev_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model, feature names and importances\n",
    "\n",
    "model_rfe_shap.estimator_.save_model(\"model_rfe_shap.json\")\n",
    "\n",
    "selected_features['rfe_shap'] = (features.to_list(), importances.to_list())\n",
    "with open('./models/features.txt', 'w') as file:\n",
    "    json.dump(selected_features, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Feature Addition (RFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
